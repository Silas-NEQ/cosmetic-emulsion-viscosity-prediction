## RELAT√ìRIO T√âCNICO FINAL

# Projeto de Previs√£o de Viscosidade em Emuls√µes Cosm√©ticas

## üí° Nota Metodol√≥gica
**Importante**: Este projeto utiliza um **dataset sint√©tico** gerado por intelig√™ncia artificial (IA) para simular dados de produ√ß√£o de emuls√µes cosm√©ticas. O objetivo principal √© demonstrar a aplica√ß√£o pr√°tica de algoritmos de machine learning em um contexto industrial, servindo como portf√≥lio t√©cnico e estudo de caso educacional.

## 1. Resumo
Este projeto desenvolveu um sistema preditivo para estimar a viscosidade final de uma emuls√£o cosm√©tica durante o processo de produ√ß√£o. Foram implementados e comparados cinco algoritmos de machine learning, sendo a Regress√£o Polinomial selecionada como modelo final devido ao seu equil√≠brio ideal entre performance preditiva e efici√™ncia computacional.

## 2. Introdu√ß√£o

### 2.1 Contexto Industrial
A viscosidade representa uma das propriedades mais cr√≠ticas em formula√ß√µes de emuls√µes cosm√©ticas, exercendo influ√™ncia direta em m√∫ltiplos aspectos do produto final:

- **Estabilidade f√≠sico-qu√≠mica**: Valores inadequados de viscosidade podem acelerar fen√¥menos de separa√ß√£o de fases como creaming e sedimenta√ß√£o (TADROS, 2013)
- **Caracter√≠sticas sensoriais**: A viscosidade determina par√¢metros como espalhabilidade, absor√ß√£o cut√¢nea e sensa√ß√£o t√°til, fatores cruciais para aceita√ß√£o do consumidor (SCHRAMM, 2005)
- **Processabilidade industrial**: Durante a manufatura, a viscosidade afeta diretamente a efici√™ncia de homogeneiza√ß√£o, bombeamento e enchimento (MYERS, 2005)

### 2.2 Problema Negocial
Varia√ß√µes nos par√¢metros de processo (temperatura, agita√ß√£o, concentra√ß√£o de emulsificantes) frequentemente resultam em inconsist√™ncias na viscosidade final, acarretando:

- Retrabalho de lotes fora de especifica√ß√£o
- Desperd√≠cio de mat√©ria-prima e insumos
- Inconsist√™ncia na qualidade do produto final
- Impacto negativo na efici√™ncia produtiva

A capacidade de prever a viscosidade final com base em vari√°veis de processo monitor√°veis permitiria interven√ß√µes proativas, otimizando o controle de qualidade e reduzindo perdas operacionais.

## 3. Metodologia

### 3.1 Coleta e Prepara√ß√£o de Dados
- **Fonte**: Dataset sint√©tico gerado por IA para replicar padr√µes reais de produ√ß√£o
- **Vari√°veis simuladas**: Par√¢metros t√≠picos de processo industrial temperatura (¬∞C), velocidade de agita√ß√£o(RPM), concentra√ß√£o(%), tempo de rea√ß√£o(min), pH, umidade(%) e viscosidade(cP)
- **Objetivo pedag√≥gico**: Desenvolver e validar metodologias de machine learning aplic√°veis a contextos industriais 

### 3.2 Pr√©-processamento
- Codifica√ß√£o de vari√°veis categ√≥ricas
- Normaliza√ß√£o de features num√©ricas
- Divis√£o estratificada: 80% treino, 20% teste

### 3.3 Modelos Implementados

**Regress√£o Polinomial**
- **Complexidade**: Grau 2

**Redes Neurais Artificiais**
- **Par√¢metros**: activation='relu', alpha=0.01, hidden_layer_sizes= (50,), learning_rate_init=0.001, solver='lbfgs', max_iter=2000

**XGBoost**
- **Par√¢metros**: n_estimators=300, max_depth=3, learning_rate=0.05

**Ensemble**
- **Composi√ß√£o**: Regress√£o Polinomial, Redes Neurais e XGBoost
- **M√©todo**: M√©dia ponderada das previs√µes

**Random Forest**
- **Par√¢metros**: n_estimators=500, max_depth=20, max_features=0.5,min_samples_leaf=1, min_samples_split=2

**SVM**
- **Par√¢metros**: Valores default. N√£o foram feitas an√°lises mais profundas, pois na primeira an√°lise o algoritmo obteve um valor muito baixo de R¬≤ (0.07) e foi descartado de imediato

## 4. Resultados e An√°lise

### 4.1 Performance Comparativa

| Modelo | R¬≤ Score |    MAE   | Ranking Performance |
|--------|----------|----------|---------------------|
| Polynomial Regression | 0.903 | 242.61 | ü•á **1¬∫ Lugar** |
| Ensemble | 0.899 | 246.98 | ü•à 2¬∫ Lugar |
| Neural Network | 0.891 | 253.26 | ü•â 3¬∫ Lugar |
| XGBoost | 0.885 | 263.96 | 4¬∫ Lugar |
| Random Forest | 0.868 | 273.80 | - |
| SVM | 0.07 | 759.49 | - |

### 4.2 An√°lise Detalhada

#### 4.2.1 Regress√£o Polinomial (Modelo Escolhido)
- **R¬≤ = 0.903**: Explica 90.3% da vari√¢ncia na viscosidade
- **MAE = 242.61**: Erro m√©dio aceit√°vel para o conjunto de dados
- **Velocidade de Processamento**: Tempo de execu√ß√£o foi de 0.08s/run

#### 4.2.2 Performance vs. Efici√™ncia
- **Ensemble**: Performance ligeiramente inferior (R¬≤ = 0.899), com custo computacional significativamente maior, devido ser uma composi√ß√£o dos 3 modelos finais. 
- **Neural Network**: Performance similar ao ensemble (R¬≤ = 0.891) com o maior tempo de processamento dentre os modelos final (27.66s/run). Uma complexidade desnecess√°ria.
- **XGBoost**: Performance inferior dentre os 3 modelos finais (R¬≤ = 0.885), nesta aplica√ß√£o espec√≠fica, por√©m segundo melhor tempo de processamento (1.17s/run)
- **Random Forest**: Modelo descartado ap√≥s o processo de valida√ß√£o cruzada devido ter o pior desempenho. Apresentou o menor valor de R¬≤ (R¬≤ = 0.868) e o maior valor de MAE (MAE = 273.80), al√©m do maior tempo de execu√ß√£o (38.41s/run).

#### 4.2.3 An√°lise Dimensional
Uma an√°lise de componentes principais (PCA) foi conduzida para avaliar o impacto da redu√ß√£o dimensional na performance dos modelos. Os resultados demonstraram que a t√©cnica n√£o apresentou benef√≠cios significativos para esse conjunto de dados espec√≠fico:

- **Regress√£o Polinomial**: O PCA resultou em aumento do tempo de processamento sem melhorias percept√≠veis nas m√©tricas de accuracy (R¬≤) ou erro (MAE)
- **Redes Neurais**: Observou-se discreta melhoria no R¬≤ e redu√ß√£o marginal no MAE, contudo, estas melhorias foram consideradas insignificantes face ao acr√©scimo computacional incorrido
- **XGBoost**: Verificou-se redu√ß√£o no tempo de execu√ß√£o, por√©m acompanhada de deteriora√ß√£o na performance preditiva, com decr√©scimo do R¬≤ e aumento do MAE

## 5. Conclus√£o
- Os 3 modelos finais demonstraram capacidade preditiva relevante (R¬≤ > 0.85)
- A rela√ß√£o n√£o-linear entre vari√°veis de processo e viscosidade foi adequadamente capturada
- A an√°lise dimensional foi descartada por n√£o agregar valor preditivo substancial, mantendo-se assim as features originais para todos os modelos finais.
- A simplicidade da Regress√£o Polinomial mostrou-se vantajosa frente a modelos mais complexos

**Decis√£o de Modelo Final**
A Regress√£o Polinomial foi selecionada como modelo definitivo devido a:
- ‚úÖ Performance l√≠der (R¬≤ = 0.903)
- ‚úÖ Efici√™ncia computacional superior (1.17 s/run)
- ‚úÖ Facilidade de implementa√ß√£o e manuten√ß√£o
- ‚úÖ Melhor custo-benef√≠cio operacional


## 6. Refer√™ncias T√©cnicas
- 1. **TADROS, T. F.** *Emulsion Science and Technology: A General Introduction*. Wiley-VCH, 2013.
2. **SCHRAMM, L. L.** *Emulsions, Foams, and Suspensions: Fundamentals and Applications*. Wiley-VCH, 2005.
3. **MYERS, D.** *Surfactant Science and Technology*. 3rd ed. Wiley, 2005.
4. **HASTIE, T.; TIBSHIRANI, R.; FRIEDMAN, J.** *The Elements of Statistical Learning*. 2nd ed. Springer, 2009.
5. **G√âRON, A.** *Hands-On Machine Learning with Scikit-Learn, Keras & TensorFlow*. 2nd ed. O'Reilly, 2019.
6. Documenta√ß√£o t√©cnica: Scikit-Learn, XGBoost, 2023.

---

**Data do Relat√≥rio**: 28/10/2025  
**Elaborado por**: Silas Nascimento 
**√Årea**: Engenheiria Qu√≠mica / Intelig√™ncia Artificial